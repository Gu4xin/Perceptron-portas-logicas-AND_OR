# Perceptron-portas-logicas-AND_OR
ATIVIDADE I.A -- PRÁTICA

1. Com a taxa de aprendizado menor (ex: 0.001) ele demora muito mais para processar; E quando o aprendizado é maior (5.0) ele processa muito mais rápido, mas o aprendizado pode se tornar instável.
2. Com poucas "epochs" o perceptron não tem tempo de ajustar os pesos podendo causar instabilidade, por mais que o output nesse caso continue normal; E com muitas "epochs" ele tem mais tempo que o suficiente para ajustar os pesos, para esse problema, então no fim essa grande quantidade de "epochs" só aumenta o tempo de processamento. 
3. Com a porta AND os resultados vão de [0, 1, 1, 1] para [0, 0, 0, 1], e o output ainda é 1
4. Extrair a função de ativação para um novo método.
5. Alterar para a função DEGRAU -- e verificar o impacto na qualidade das respostas
